{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Vaidurya Samaga\n",
        "\n",
        "SRN: PES2UG23CS668\n",
        "\n",
        "Section:K"
      ],
      "metadata": {
        "id": "hvI0XL6NehX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P9biDbxe16M",
        "outputId": "0d0c0893-3046-43a7-d990-f941ef7dd378"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2a: The Anatomy of a Prompt"
      ],
      "metadata": {
        "id": "LCiDClIcfVwJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SFbBX3veFmt",
        "outputId": "a3709215-fc82-416a-e56e-a3fe46d74873"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "# Using Low Temp for consistent comparison\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task = \"Write a rejection email to a candidate.\"\n",
        "\n",
        "print(\"--- LAZY PROMPT ---\")\n",
        "print(llm.invoke(task).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OLIlhs0fCPy",
        "outputId": "f2221975-9284-4694-99c6-f4a43c40d6cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAZY PROMPT ---\n",
            "Here are a few options for a rejection email, ranging from a standard, polite version to one that offers a bit more encouragement. Choose the one that best fits your company's culture and the stage of the hiring process.\n",
            "\n",
            "---\n",
            "\n",
            "**Option 1: Standard & Polite (Most Common)**\n",
            "\n",
            "**Subject: Update on Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to [interview with our team / submit your application].\n",
            "\n",
            "We appreciate you sharing your qualifications and experience with us. We received a large number of applications for this role, and after careful consideration, we have decided to move forward with other candidates whose qualifications and experience were a closer match for the specific requirements of this role at this time.\n",
            "\n",
            "This was a very competitive search, and we truly appreciate the time and effort you invested in the process.\n",
            "\n",
            "We wish you the best of luck in your job search and future endeavors.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Option 2: Early Stage Rejection (No Interview)**\n",
            "\n",
            "**Subject: Regarding Your Application for the [Job Title] Position at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for submitting your application.\n",
            "\n",
            "We appreciate you sharing your resume and qualifications with us. We received a significant number of applications, and after careful review, we have decided to move forward with other candidates whose experience and skills were a closer fit for the specific requirements of this role.\n",
            "\n",
            "We wish you the best of luck in your job search and future career.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "\n",
            "---\n",
            "\n",
            "**Option 3: With Encouragement for Future Roles**\n",
            "\n",
            "**Subject: Update on Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to [interview with our team / submit your application]. We truly enjoyed learning more about your background and experience.\n",
            "\n",
            "We received a high volume of applications from many talented individuals, and the selection process was very competitive. While your qualifications are impressive, we have decided to move forward with other candidates whose profiles were a closer match for the specific needs of this role at this time.\n",
            "\n",
            "We encourage you to keep an eye on our careers page at [Link to Careers Page] for future opportunities that may align with your skills and experience.\n",
            "\n",
            "We wish you all the best in your job search and future career.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Key things to remember when sending a rejection email:**\n",
            "\n",
            "*   **Be Prompt:** Send it as soon as a decision is made.\n",
            "*   **Be Clear:** Don't leave room for ambiguity.\n",
            "*   **Be Polite and Professional:** Always maintain a respectful tone.\n",
            "*   **Be Concise:** Get straight to the point without being overly brief or cold.\n",
            "*   **Avoid Specific Reasons:** Do not give detailed reasons for rejection (e.g., \"we felt you lacked X skill,\" \"your personality wasn't a fit\"). This can open the door to legal challenges or unnecessary debate. Stick to general statements like \"closer match,\" \"specific requirements,\" or \"highly competitive.\"\n",
            "*   **Personalize:** Always use the candidate's name and the specific job title.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "structured_prompt = \"\"\"\n",
        "# Context\n",
        "You are an HR Manager at a quirky startup called 'RocketBoots'.\n",
        "\n",
        "# Objective\n",
        "Write a rejection email to a candidate named Bob.\n",
        "\n",
        "# Constraints\n",
        "1. Be extremely brief (under 50 words).\n",
        "2. Do NOT say 'we found someone better'. Say 'the role changed'.\n",
        "3. Sign off with 'Keep flying'.\n",
        "\n",
        "# Output Format\n",
        "Plain text, no subject line.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- STRUCTURED PROMPT ---\")\n",
        "print(llm.invoke(structured_prompt).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5eDTm08fJt_",
        "outputId": "6f93f8da-becf-44bd-fa69-69586c9ba649"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STRUCTURED PROMPT ---\n",
            "Hi Bob,\n",
            "\n",
            "Thank you for your interest in RocketBoots.\n",
            "\n",
            "We appreciate you taking the time to interview. However, the role's requirements have changed significantly since your application. We wish you the best in your job search.\n",
            "\n",
            "Keep flying.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2b: Zero-Shot to Few-Shot"
      ],
      "metadata": {
        "id": "8v0ecznefX87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.5)"
      ],
      "metadata": {
        "id": "g9aDZM43fR0l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_zero = \"Combine 'Angry' and 'Hungry' into a funny new word.\"\n",
        "print(f\"Zero-Shot: {llm.invoke(prompt_zero).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aly23aLEfetF",
        "outputId": "8da7fb9c-21d1-4f46-b558-47beb4e8b61d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot: The most common and widely accepted funny word for that is **Hangry**!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_few = \"\"\"\n",
        "Combine words into a funny new word. Give a sarcastic definition.\n",
        "\n",
        "Input: Breakfast + Lunch\n",
        "Output: Brunch (An excuse to drink alcohol before noon)\n",
        "\n",
        "Input: Chill + Relax\n",
        "Output: Chillax (What annoying people say when you are panic attacks)\n",
        "\n",
        "Input: Angry + Hungry\n",
        "Output:\n",
        "\"\"\"\n",
        "print(f\"Few-Shot: {llm.invoke(prompt_few).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7U1-Wk1fiOc",
        "outputId": "3badeea3-586e-4a62-a3e0-2fd41761a476"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-Shot: Output: Hangry (The completely valid excuse for being a terrible human being until you've had a snack.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2c: Advanced Templates & Theory"
      ],
      "metadata": {
        "id": "dEX5xmaSfm8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "iwHtzqU-flUK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "# 1. Our Database of Examples\n",
        "examples = [\n",
        "    {\"input\": \"The internet is down.\", \"output\": \"We are observing connectivity latency.\"},\n",
        "    {\"input\": \"This code implies a bug.\", \"output\": \"The logic suggests unintended behavior.\"},\n",
        "    {\"input\": \"I hate this feature.\", \"output\": \"This feature does not align with my preferences.\"},\n",
        "]\n",
        "\n",
        "# 2. Template for ONE example\n",
        "example_fmt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"ai\", \"{output}\")\n",
        "])\n",
        "\n",
        "# 3. The Few-Shot Container\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_fmt,\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "# 4. The Final Chain\n",
        "final_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a Corpo-Speak Translator. Rewrite the input to sound professional.\"),\n",
        "    few_shot_prompt,      # Inject examples here\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "chain = final_prompt | llm\n",
        "\n",
        "print(chain.invoke({\"text\": \"This app sucks.\"}).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTuwnLsUfsAc",
        "outputId": "dbb2e779-6fa1-4955-ef20-09b075b4e104"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This application presents opportunities for enhancement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ASSIGNMENT(Analysis)"
      ],
      "metadata": {
        "id": "GkRUJOkignLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    FewShotChatMessagePromptTemplate\n",
        ")\n",
        "\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n"
      ],
      "metadata": {
        "id": "MFVYG6deheOl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"input\": \"Give me the file\",\n",
        "        \"output\": \"Could you please give me the file?\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Close the door\",\n",
        "        \"output\": \"Could you please close the door?\"\n",
        "    }\n",
        "]\n"
      ],
      "metadata": {
        "id": "Qd6Y8AU6gk6m"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"ai\", \"{output}\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "0YjrGy4sgv0P"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt\n",
        ")\n"
      ],
      "metadata": {
        "id": "8jma77kDgzx5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Convert the given sentence into polite English.\"),\n",
        "    few_shot_prompt,\n",
        "    (\"human\", \"{sentence}\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "h8fK4qXAg2Y2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "chain = final_prompt | llm | StrOutputParser()\n"
      ],
      "metadata": {
        "id": "Iu2nV1Y4g3is"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"sentence\": \"Send me the report\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ipWs7oaUhzwK",
        "outputId": "bc5b2aa8-fc3c-4996-e84a-bc4ae0588ef0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Could you please send me the report?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}